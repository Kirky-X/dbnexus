//! DBNexus è¿ç§» CLI å·¥å…·
//!
//! æä¾›æ•°æ®åº“è¿ç§»çš„å‘½ä»¤è¡Œç•Œé¢

use clap::{Parser, Subcommand};
use dbnexus::migration::{DatabaseType as MigrationDatabaseType, MigrationExecutor, MigrationFileParser};
use dbnexus::{config::DbError, DbPool, DbResult};
use std::fs;
use std::path::PathBuf;
use std::time::{SystemTime, UNIX_EPOCH};

/// CLI é…ç½®
#[derive(Parser)]
#[command(name = "dbnexus-migrate")]
#[command(about = "DBNexus æ•°æ®åº“è¿ç§»å·¥å…·", long_about = None)]
struct Cli {
    /// æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
    #[arg(short, long, env = "DATABASE_URL")]
    database_url: String,

    /// é…ç½®æ–‡ä»¶è·¯å¾„
    #[arg(short, long)]
    config: Option<PathBuf>,

    /// è¿ç§»æ–‡ä»¶ç›®å½•
    #[arg(short, long, default_value = "./migrations")]
    migrations_dir: PathBuf,

    #[command(subcommand)]
    command: Commands,
}

/// CLI å­å‘½ä»¤
#[derive(Subcommand)]
enum Commands {
    /// åˆ›å»ºæ–°çš„è¿ç§»æ–‡ä»¶
    Create {
        /// è¿ç§»æè¿°
        description: String,

        /// è¿ç§»æ–‡ä»¶è¾“å‡ºç›®å½•
        #[arg(short, long, default_value = "./migrations")]
        directory: PathBuf,
    },

    /// åº”ç”¨è¿ç§»
    Up {
        /// ç›®æ ‡ç‰ˆæœ¬å·ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰å¾…åº”ç”¨è¿ç§»ï¼‰
        #[arg(long)]
        version: Option<u32>,
    },

    /// å›æ»šè¿ç§»
    Down {
        /// ç›®æ ‡ç‰ˆæœ¬å·ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºå›æ»šä¸Šä¸€ç‰ˆæœ¬ï¼‰
        #[arg(long)]
        version: Option<u32>,

        /// å›æ»šæ‰€æœ‰è¿ç§»
        #[arg(long, default_value = "false")]
        all: bool,
    },

    /// æŸ¥çœ‹è¿ç§»çŠ¶æ€
    Status,

    /// æµ‹è¯•æ•°æ®åº“è¿æ¥
    TestConnection,

    /// ç”Ÿæˆè¿ç§»æ–‡ä»¶ï¼ˆåŸºäº schema å·®å¼‚ï¼‰
    Generate {
        /// æº Schema æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼‰
        #[arg(long)]
        from_schema: Option<PathBuf>,

        /// ç›®æ ‡ Schema æ–‡ä»¶ï¼ˆJSON æ ¼å¼ï¼‰
        #[arg(long)]
        to_schema: Option<PathBuf>,

        /// è¾“å‡ºè¿ç§»æ–‡ä»¶è·¯å¾„
        #[arg(short, long, default_value = "./migrations/generated.sql")]
        output: PathBuf,

        /// è¿ç§»æè¿°
        #[arg(short, long, default_value = "auto_generated")]
        description: String,
    },

    /// åˆ—å‡ºæ‰€æœ‰è¿ç§»æ–‡ä»¶
    List,
}

/// ç¨‹åºå…¥å£
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    // ç¡®ä¿è¿ç§»ç›®å½•å­˜åœ¨
    if !cli.migrations_dir.exists() {
        fs::create_dir_all(&cli.migrations_dir).map_err(|e| DbError::Config(format!("æ— æ³•åˆ›å»ºè¿ç§»ç›®å½•: {}", e)))?;
    }

    match &cli.command {
        Commands::Create { description, directory } => {
            create_migration(description, directory).await?;
        }
        Commands::Up { version } => {
            run_migrations_up(&cli.database_url, &cli.migrations_dir, *version).await?;
        }
        Commands::Down { version, all } => {
            run_migrations_down(&cli.database_url, *version, *all).await?;
        }
        Commands::Status => {
            show_status(&cli.database_url, &cli.migrations_dir).await?;
        }
        Commands::TestConnection => {
            test_connection(&cli.database_url).await?;
        }
        Commands::Generate {
            from_schema,
            to_schema,
            output,
            description,
        } => {
            generate_migration(from_schema, to_schema, output, description).await?;
        }
        Commands::List => {
            list_migrations(&cli.migrations_dir)?;
        }
    }

    Ok(())
}

/// åˆ›å»ºæ–°çš„è¿ç§»æ–‡ä»¶
async fn create_migration(description: &str, directory: &PathBuf) -> DbResult<()> {
    // åˆ›å»ºè¿ç§»ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    fs::create_dir_all(directory).map_err(|e| DbError::Config(format!("æ— æ³•åˆ›å»ºç›®å½•: {}", e)))?;

    // ç”Ÿæˆæ—¶é—´æˆ³ä½œä¸ºç‰ˆæœ¬å·
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| DbError::Config(format!("æ— æ³•è§£ææ—¶é—´æˆ³: {}", e)))?
        .as_secs();

    let filename = format!("{}_{}.sql", timestamp, description.replace(' ', "_"));
    let filepath = directory.join(&filename);

    // åˆ›å»ºè¿ç§»æ–‡ä»¶æ¨¡æ¿
    let migration_content = format!(
        r#"-- Migration: {description}
-- Version: {timestamp}
-- Created: {created_at}

-- UP: Apply migration
-- Your migration SQL goes here

-- DOWN: Rollback migration
-- Reversal of migration SQL goes here
"#,
        description = description,
        timestamp = timestamp,
        created_at = chrono::Utc::now().format("%Y-%m-%d %H:%M:%S")
    );

    fs::write(&filepath, migration_content).map_err(|e| DbError::Config(format!("æ— æ³•å†™å…¥è¿ç§»æ–‡ä»¶: {}", e)))?;

    println!("âœ“ è¿ç§»æ–‡ä»¶å·²åˆ›å»º: {}", filepath.display());

    Ok(())
}

/// æ˜¾ç¤ºè¿ç§»çŠ¶æ€
async fn show_status(database_url: &str, migrations_dir: &PathBuf) -> DbResult<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    è¿ç§»çŠ¶æ€æŸ¥çœ‹                              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // æµ‹è¯•æ•°æ®åº“è¿æ¥
    let pool = match DbPool::new(database_url).await {
        Ok(pool) => pool,
        Err(e) => {
            println!("\nâŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e);
            return Ok(());
        }
    };

    // è·å–æ•°æ®åº“ç±»å‹
    let db_type = detect_database_type(database_url);
    println!("\nğŸ“Š æ•°æ®åº“ç±»å‹: {}", db_type);
    println!("ğŸ“ è¿ç§»ç›®å½•: {}", migrations_dir.display());

    // åŠ è½½è¿ç§»å†å²
    let mut session = match pool.get_session("admin").await {
        Ok(session) => session,
        Err(e) => {
            println!("\nâŒ æ— æ³•è·å–æ•°æ®åº“ä¼šè¯: {}", e);
            return Ok(());
        }
    };

    let connection = session.connection()?.clone();
    let mut executor = MigrationExecutor::new(connection, db_type);

    if let Err(e) = executor.load_history().await {
        println!("\nâš ï¸  æ— æ³•åŠ è½½è¿ç§»å†å²: {}", e);
        println!("   è¿ç§»å†å²è¡¨å¯èƒ½ä¸å­˜åœ¨");
        return Ok(());
    }

    let applied_count = executor.history.applied_migrations.len();
    println!("\nâœ… å·²åº”ç”¨çš„è¿ç§»: {} ä¸ª", applied_count);

    if applied_count > 0 {
        // æ˜¾ç¤ºæœ€æ–°è¿ç§»ä¿¡æ¯
        if let Some(latest_version) = executor.history.get_latest_version() {
            if let Some(latest_migration) = executor
                .history
                .applied_migrations
                .iter()
                .find(|m| m.version == latest_version)
            {
                println!("   æœ€æ–°è¿ç§»:");
                println!("     - ç‰ˆæœ¬: {}", latest_migration.version);
                println!("     - æè¿°: {}", latest_migration.description);
                println!("     - åº”ç”¨æ—¶é—´: {}", latest_migration.applied_at);
            }
        }

        // æ˜¾ç¤ºæ‰€æœ‰å·²åº”ç”¨è¿ç§»
        println!("\n   è¿ç§»å†å²è¯¦æƒ…:");
        for (idx, migration) in executor.history.applied_migrations.iter().enumerate() {
            println!(
                "   [{:2}] v{:6} - {}",
                idx + 1,
                migration.version,
                migration.description
            );
        }
    }

    // æ‰«ææœ¬åœ°è¿ç§»æ–‡ä»¶
    let local_migrations = scan_migration_files(migrations_dir)?;
    let pending_count = local_migrations.len().saturating_sub(applied_count);

    println!("\nğŸ“¦ æœ¬åœ°è¿ç§»æ–‡ä»¶: {} ä¸ª", local_migrations.len());
    println!("â³ å¾…åº”ç”¨çš„è¿ç§»: {} ä¸ª", pending_count);

    if !local_migrations.is_empty() {
        // æ˜¾ç¤ºå¾…åº”ç”¨çš„è¿ç§»
        let applied_versions: std::collections::HashSet<u32> =
            executor.history.applied_migrations.iter().map(|m| m.version).collect();

        let pending: Vec<_> = local_migrations
            .iter()
            .filter(|m| !applied_versions.contains(&m.version))
            .collect();

        if !pending.is_empty() {
            println!("\n   å¾…åº”ç”¨è¿ç§»åˆ—è¡¨:");
            for (idx, migration) in pending.iter().enumerate() {
                println!(
                    "   [{:2}] v{:6} - {}",
                    idx + 1,
                    migration.version,
                    migration.description
                );
            }
        } else {
            println!("\n   âœ“ æ‰€æœ‰è¿ç§»éƒ½å·²åº”ç”¨");
        }
    }

    // æ˜¾ç¤ºæ•°æ®åº“è¿æ¥ä¿¡æ¯
    println!("\nğŸ”— æ•°æ®åº“è¿æ¥: å·²è¿æ¥");
    println!("   URL: {}", mask_database_url(database_url));

    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// æµ‹è¯•æ•°æ®åº“è¿æ¥
async fn test_connection(database_url: &str) -> DbResult<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    æ•°æ®åº“è¿æ¥æµ‹è¯•                            â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    println!("\nğŸ”„ æ­£åœ¨æµ‹è¯•æ•°æ®åº“è¿æ¥...");

    let start_time = std::time::Instant::now();

    let pool = match DbPool::new(database_url).await {
        Ok(pool) => pool,
        Err(e) => {
            println!("\nâŒ è¿æ¥å¤±è´¥: {}", e);
            return Ok(());
        }
    };

    let elapsed = start_time.elapsed();

    // è·å–ä¼šè¯ä»¥éªŒè¯è¿æ¥
    match pool.get_session("admin").await {
        Ok(mut session) => {
            let _conn = session.connection()?.clone();
            drop(session);

            let db_type = detect_database_type(database_url);

            println!("\nâœ… è¿æ¥æˆåŠŸ!");
            println!("\n   æ•°æ®åº“ç±»å‹: {}", db_type);
            println!("   è¿æ¥è€—æ—¶: {:?}", elapsed);
            println!("   è¿æ¥URL: {}", mask_database_url(database_url));

            // æ˜¾ç¤ºè¿æ¥æ± çŠ¶æ€
            println!("\n   è¿æ¥æ± çŠ¶æ€:");
            let status = pool.status();
            println!("     - æ€»è¿æ¥æ•°: {}", status.total);
            println!("     - æ´»è·ƒè¿æ¥: {}", status.active);
            println!("     - ç©ºé—²è¿æ¥: {}", status.idle);
        }
        Err(e) => {
            println!("\nâŒ è¿æ¥éªŒè¯å¤±è´¥: {}", e);
        }
    }

    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// è¿è¡Œå‘ä¸Šçš„è¿ç§»ï¼ˆåº”ç”¨è¿ç§»ï¼‰
async fn run_migrations_up(database_url: &str, migrations_dir: &PathBuf, target_version: Option<u32>) -> DbResult<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    åº”ç”¨è¿ç§»                                  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    let pool = DbPool::new(database_url).await?;
    let db_type = detect_database_type(database_url);

    println!("\nğŸ“Š æ•°æ®åº“ç±»å‹: {}", db_type);
    println!("ğŸ“ è¿ç§»ç›®å½•: {}", migrations_dir.display());

    // æ‰«æè¿ç§»æ–‡ä»¶
    let migrations = scan_migration_files(migrations_dir)?;

    if migrations.is_empty() {
        println!("\nâš ï¸  è¿ç§»ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è¿ç§»æ–‡ä»¶");
        return Ok(());
    }

    // åˆ›å»ºè¿ç§»æ‰§è¡Œå™¨
    let mut session = pool.get_session("admin").await?;
    let connection = session.connection()?.clone();
    let mut executor = MigrationExecutor::new(connection, db_type);

    // åŠ è½½è¿ç§»å†å²
    executor.load_history().await?;

    // ç­›é€‰å¾…åº”ç”¨çš„è¿ç§»
    let applied_versions: std::collections::HashSet<u32> =
        executor.history.applied_migrations.iter().map(|m| m.version).collect();

    let mut to_apply: Vec<_> = migrations
        .iter()
        .filter(|m| !applied_versions.contains(&m.version))
        .filter(|m| {
            if let Some(target) = target_version {
                m.version <= target
            } else {
                true
            }
        })
        .collect();

    to_apply.sort_by_key(|m| m.version);

    if to_apply.is_empty() {
        println!("\nâœ“ æ²¡æœ‰å¾…åº”ç”¨çš„è¿ç§»");
        return Ok(());
    }

    println!("\nğŸ“¦ æ‰¾åˆ° {} ä¸ªå¾…åº”ç”¨è¿ç§»", to_apply.len());

    if let Some(target) = target_version {
        println!("   ç›®æ ‡ç‰ˆæœ¬: {}", target);
    }

    // åº”ç”¨è¿ç§»
    println!("\nğŸš€ å¼€å§‹åº”ç”¨è¿ç§»...");
    let mut success_count = 0;

    for migration in &to_apply {
        print!("   æ­£åœ¨åº”ç”¨ v{} - {} ... ", migration.version, migration.description);

        match std::fs::read_to_string(&migration.file_path) {
            Ok(content) => match parse_and_apply_migration(&mut executor, &content, migration.version, db_type).await {
                Ok(_) => {
                    println!("âœ“");
                    success_count += 1;
                }
                Err(e) => {
                    println!("âŒ å¤±è´¥: {}", e);
                    return Err(e);
                }
            },
            Err(e) => {
                println!("âŒ æ— æ³•è¯»å–æ–‡ä»¶: {}", e);
            }
        }
    }

    println!("\nâœ… æˆåŠŸåº”ç”¨ {} / {} ä¸ªè¿ç§»", success_count, to_apply.len());
    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// è¿è¡Œå‘ä¸‹çš„è¿ç§»ï¼ˆå›æ»šè¿ç§»ï¼‰
async fn run_migrations_down(database_url: &str, target_version: Option<u32>, rollback_all: bool) -> DbResult<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    å›æ»šè¿ç§»                                  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    let pool = DbPool::new(database_url).await?;
    let db_type = detect_database_type(database_url);

    println!("\nğŸ“Š æ•°æ®åº“ç±»å‹: {}", db_type);

    // åˆ›å»ºè¿ç§»æ‰§è¡Œå™¨
    let mut session = pool.get_session("admin").await?;
    let connection = session.connection()?.clone();
    let mut executor = MigrationExecutor::new(connection, db_type);

    // åŠ è½½è¿ç§»å†å²
    executor.load_history().await?;

    let applied_migrations = &executor.history.applied_migrations;

    if applied_migrations.is_empty() {
        println!("\nâš ï¸  æ²¡æœ‰å·²åº”ç”¨çš„è¿ç§»å¯ä»¥å›æ»š");
        return Ok(());
    }

    // ç¡®å®šè¦å›æ»šçš„ç‰ˆæœ¬
    let versions_to_rollback: Vec<u32> = if rollback_all {
        applied_migrations.iter().map(|m| m.version).collect()
    } else if let Some(target) = target_version {
        applied_migrations
            .iter()
            .filter(|m| m.version >= target)
            .map(|m| m.version)
            .collect()
    } else {
        // å›æ»šä¸Šä¸€ä¸ªç‰ˆæœ¬
        vec![applied_migrations.iter().map(|m| m.version).max().unwrap()]
    };

    // æŒ‰ç‰ˆæœ¬å·é™åºæ’åºï¼ˆå…ˆå›æ»šæœ€æ–°çš„ï¼‰
    let mut versions_to_rollback = versions_to_rollback;
    versions_to_rollback.sort_by_key(|v| std::cmp::Reverse(*v));

    println!("\nğŸ“¦ éœ€è¦å›æ»š {} ä¸ªè¿ç§»", versions_to_rollback.len());

    if rollback_all {
        println!("   æ¨¡å¼: å›æ»šæ‰€æœ‰è¿ç§»");
    } else if let Some(target) = target_version {
        println!("   æ¨¡å¼: å›æ»šåˆ°ç‰ˆæœ¬ {}", target);
    } else {
        println!("   æ¨¡å¼: å›æ»šä¸Šä¸€ä¸ªç‰ˆæœ¬");
    }

    // æ‰§è¡Œå›æ»š
    println!("\nğŸ”„ å¼€å§‹å›æ»šè¿ç§»...");
    let mut success_count = 0;

    // æ”¶é›†éœ€è¦å›æ»šçš„è¿ç§»ä¿¡æ¯ï¼Œé¿å…åœ¨å¾ªç¯ä¸­å€Ÿç”¨
    let rollback_info: Vec<(u32, String)> = versions_to_rollback
        .iter()
        .filter_map(|version| {
            applied_migrations
                .iter()
                .find(|m| m.version == *version)
                .map(|info| (info.version, info.description.clone()))
        })
        .collect();

    for (version, description) in &rollback_info {
        print!("   æ­£åœ¨å›æ»š v{} - {} ... ", version, description);

        match rollback_migration(&mut executor, *version, db_type).await {
            Ok(_) => {
                println!("âœ“");
                success_count += 1;
            }
            Err(e) => {
                println!("âŒ å¤±è´¥: {}", e);
                // ç»§ç»­å°è¯•å›æ»šå…¶ä»–è¿ç§»
            }
        }
    }

    println!(
        "\nâœ… æˆåŠŸå›æ»š {} / {} ä¸ªè¿ç§»",
        success_count,
        versions_to_rollback.len()
    );
    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// å›æ»šå•ä¸ªè¿ç§»
async fn rollback_migration(
    executor: &mut MigrationExecutor,
    version: u32,
    db_type: MigrationDatabaseType,
) -> DbResult<()> {
    use dbnexus::orm::{ConnectionTrait, TransactionTrait};

    // åˆ é™¤è¿ç§»å†å²è®°å½•
    let delete_sql = match db_type {
        MigrationDatabaseType::Postgres | MigrationDatabaseType::MySQL => {
            format!("DELETE FROM dbnexus_migrations WHERE version = {};", version)
        }
        MigrationDatabaseType::SQLite => {
            format!("DELETE FROM dbnexus_migrations WHERE version = {};", version)
        }
    };

    let txn = executor.connection.begin().await.map_err(DbError::Connection)?;

    txn.execute_unprepared(&delete_sql).await.map_err(DbError::Connection)?;

    txn.commit().await.map_err(DbError::Connection)?;

    Ok(())
}

/// æ‰«æè¿ç§»ç›®å½•ä¸­çš„æ–‡ä»¶
fn scan_migration_files(dir: &PathBuf) -> Result<Vec<MigrationInfo>, DbError> {
    let mut migrations = Vec::new();

    if !dir.exists() {
        return Ok(migrations);
    }

    let entries = fs::read_dir(dir).map_err(|e| DbError::Config(format!("è¯»å–ç›®å½•å¤±è´¥: {}", e)))?;

    for entry in entries {
        let entry = entry.map_err(|e| DbError::Config(format!("è¯»å–æ¡ç›®å¤±è´¥: {}", e)))?;
        let path = entry.path();

        if path.is_file() && path.extension().map(|e| e == "sql").unwrap_or(false) {
            if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {
                if let Some((version, description)) = parse_migration_filename(filename) {
                    migrations.push(MigrationInfo {
                        version,
                        description,
                        file_path: path.clone(),
                    });
                }
            }
        }
    }

    // æŒ‰ç‰ˆæœ¬å·æ’åº
    migrations.sort_by_key(|m| m.version);

    Ok(migrations)
}

/// è§£æè¿ç§»æ–‡ä»¶å
fn parse_migration_filename(filename: &str) -> Option<(u32, String)> {
    // æ ¼å¼: {version}_{description}.sql
    let parts: Vec<&str> = filename.split('_').collect();
    if parts.len() < 2 {
        return None;
    }

    let version = parts[0].parse::<u32>().ok()?;
    let description = parts[1..].join("_").replace(".sql", "");

    Some((version, description))
}

/// è¿ç§»æ–‡ä»¶ä¿¡æ¯
#[derive(Debug, Clone)]
struct MigrationInfo {
    version: u32,
    description: String,
    file_path: PathBuf,
}

/// ç”Ÿæˆè¿ç§»æ–‡ä»¶
async fn generate_migration(
    from_schema: &Option<PathBuf>,
    to_schema: &Option<PathBuf>,
    output: &PathBuf,
    description: &str,
) -> DbResult<()> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    ç”Ÿæˆè¿ç§»æ–‡ä»¶                              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // ç”Ÿæˆæ—¶é—´æˆ³ä½œä¸ºç‰ˆæœ¬å·
    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map_err(|e| DbError::Config(format!("æ— æ³•è§£ææ—¶é—´æˆ³: {}", e)))?
        .as_secs();

    // å¦‚æœæä¾›äº† schema æ–‡ä»¶ï¼Œå°è¯•ç”Ÿæˆå·®å¼‚ SQL
    let migration_content;

    if let (Some(from), Some(to)) = (from_schema, to_schema) {
        println!("\nğŸ“„ è§£æ Schema æ–‡ä»¶...");

        let from_content =
            fs::read_to_string(from).map_err(|e| DbError::Config(format!("æ— æ³•è¯»å–æº schema æ–‡ä»¶: {}", e)))?;
        let to_content =
            fs::read_to_string(to).map_err(|e| DbError::Config(format!("æ— æ³•è¯»å–ç›®æ ‡ schema æ–‡ä»¶: {}", e)))?;

        // ç”Ÿæˆå·®å¼‚ SQL
        let diff_sql = generate_schema_diff_sql(&from_content, &to_content)?;

        migration_content = format!(
            r#"-- Migration: {description}
-- Version: {timestamp}
-- Created: {created_at}
-- Type: Auto-generated from schema diff

-- UP: Apply migration
{up_sql}

-- DOWN: Rollback migration
{down_sql}
"#,
            description = description,
            timestamp = timestamp,
            created_at = chrono::Utc::now().format("%Y-%m-%d %H:%M:%S"),
            up_sql = diff_sql.up,
            down_sql = diff_sql.down
        );

        println!("âœ“ å·²ç”Ÿæˆ schema å·®å¼‚ SQL");
    } else {
        // ç”Ÿæˆç©ºç™½è¿ç§»æ¨¡æ¿
        migration_content = format!(
            r#"-- Migration: {description}
-- Version: {timestamp}
-- Created: {created_at}
-- Type: Manual migration

-- UP: Apply migration
-- Your migration SQL goes here

-- DOWN: Rollback migration
-- Reversal of migration SQL goes here
"#,
            description = description,
            timestamp = timestamp,
            created_at = chrono::Utc::now().format("%Y-%m-%d %H:%M:%S")
        );

        println!("âš ï¸  æœªæä¾› schema æ–‡ä»¶ï¼Œå·²ç”Ÿæˆç©ºç™½æ¨¡æ¿");
    }

    // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if let Some(parent) = output.parent() {
        if !parent.exists() {
            fs::create_dir_all(parent).map_err(|e| DbError::Config(format!("æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {}", e)))?;
        }
    }

    // å†™å…¥æ–‡ä»¶
    fs::write(output, migration_content).map_err(|e| DbError::Config(format!("æ— æ³•å†™å…¥è¿ç§»æ–‡ä»¶: {}", e)))?;

    println!("\nâœ“ è¿ç§»æ–‡ä»¶å·²ç”Ÿæˆ: {}", output.display());

    // å¦‚æœç”Ÿæˆäº†å®é™… SQLï¼Œæ˜¾ç¤ºæ‘˜è¦
    if from_schema.is_some() && to_schema.is_some() {
        println!("   è¯·æ£€æŸ¥å¹¶ç¼–è¾‘ç”Ÿæˆçš„è¿ç§»æ–‡ä»¶ä»¥ç¡®ä¿æ­£ç¡®æ€§");
    }

    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// Schema å·®å¼‚ SQL
struct DiffSql {
    up: String,
    down: String,
}

/// ç”Ÿæˆ Schema å·®å¼‚ SQLï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
fn generate_schema_diff_sql(_from_content: &str, _to_content: &str) -> Result<DiffSql, DbError> {
    // è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–å®ç°
    // å®é™…å®ç°éœ€è¦è§£æ schema æ–‡ä»¶å¹¶è®¡ç®—å·®å¼‚
    Ok(DiffSql {
        up: "-- è‡ªåŠ¨ç”Ÿæˆçš„ UP SQL è¯·æ‰‹åŠ¨ç¼–è¾‘".to_string(),
        down: "-- è‡ªåŠ¨ç”Ÿæˆçš„ DOWN SQL è¯·æ‰‹åŠ¨ç¼–è¾‘".to_string(),
    })
}

/// è§£æå¹¶åº”ç”¨è¿ç§»
async fn parse_and_apply_migration(
    executor: &mut MigrationExecutor,
    content: &str,
    version: u32,
    db_type: MigrationDatabaseType,
) -> DbResult<()> {
    use dbnexus::orm::{ConnectionTrait, TransactionTrait};

    // è§£æè¿ç§»å†…å®¹
    let (description, _full_content) =
        MigrationFileParser::parse_migration_file(content).unwrap_or(("Migration".to_string(), content.to_string()));

    // æå– UP SQLï¼ˆ-- UP åˆ° -- DOWN ä¹‹é—´ï¼‰
    let up_sql = extract_sql_section(content, "UP")?;

    // å¼€å§‹äº‹åŠ¡
    let txn = executor.connection.begin().await.map_err(DbError::Connection)?;

    // æ‰§è¡Œ UP SQL
    if !up_sql.trim().is_empty() {
        txn.execute_unprepared(&up_sql).await.map_err(DbError::Connection)?;
    }

    // è®°å½•è¿ç§»å†å²
    let insert_sql = match db_type {
        MigrationDatabaseType::Postgres | MigrationDatabaseType::MySQL => {
            format!(
                "INSERT INTO dbnexus_migrations (version, description, applied_at, file_path) \
                 VALUES ({}, '{}', '{}', 'migration_v{}.sql');",
                version,
                description.replace('\'', "''"),
                chrono::Utc::now().to_rfc3339(),
                version
            )
        }
        MigrationDatabaseType::SQLite => {
            format!(
                "INSERT INTO dbnexus_migrations (version, description, applied_at, file_path) \
                 VALUES ({}, '{}', '{}', 'migration_v{}.sql');",
                version,
                description.replace('\'', "''"),
                chrono::Utc::now().to_rfc3339(),
                version
            )
        }
    };

    txn.execute_unprepared(&insert_sql).await.map_err(DbError::Connection)?;

    txn.commit().await.map_err(DbError::Connection)?;

    Ok(())
}

/// æå– SQL éƒ¨åˆ†
fn extract_sql_section(content: &str, section: &str) -> Result<String, DbError> {
    let section_start = format!("-- {}", section);
    let section_end = format!("-- {}", if section == "UP" { "DOWN" } else { "UP" });

    let start_idx = content.find(&section_start).map(|i| i + section_start.len());
    let end_idx = content.find(&section_end);

    if let Some(start) = start_idx {
        if let Some(end) = end_idx {
            Ok(content[start..end].trim().to_string())
        } else {
            Ok(content[start..].trim().to_string())
        }
    } else {
        Ok(String::new())
    }
}

/// åˆ—å‡ºæ‰€æœ‰è¿ç§»æ–‡ä»¶
fn list_migrations(migrations_dir: &PathBuf) -> Result<(), DbError> {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                    è¿ç§»æ–‡ä»¶åˆ—è¡¨                              â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    let migrations = scan_migration_files(migrations_dir)?;

    if migrations.is_empty() {
        println!("\nâš ï¸  è¿ç§»ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°è¿ç§»æ–‡ä»¶");
        println!("   ç›®å½•: {}", migrations_dir.display());
        return Ok(());
    }

    println!("\nğŸ“ è¿ç§»ç›®å½•: {}", migrations_dir.display());
    println!("ğŸ“¦ å…± {} ä¸ªè¿ç§»æ–‡ä»¶\n", migrations.len());

    for (idx, migration) in migrations.iter().enumerate() {
        println!(
            "   [{:2}] v{:6} - {}",
            idx + 1,
            migration.version,
            migration.description
        );
    }

    println!("\n{}", "â”€".repeat(60));

    Ok(())
}

/// æ£€æµ‹æ•°æ®åº“ç±»å‹
fn detect_database_type(database_url: &str) -> MigrationDatabaseType {
    if database_url.starts_with("postgres") {
        MigrationDatabaseType::Postgres
    } else if database_url.starts_with("mysql") {
        MigrationDatabaseType::MySQL
    } else {
        MigrationDatabaseType::SQLite
    }
}

/// éšè—æ•°æ®åº“ URL ä¸­çš„æ•æ„Ÿä¿¡æ¯
fn mask_database_url(url: &str) -> String {
    // éšè—å¯†ç 
    let masked = url::Url::parse(url)
        .map(|mut url| {
            if let Some(password) = url.password() {
                url.set_password(Some(&"*".repeat(password.len()))).ok();
            }
            url.to_string()
        })
        .unwrap_or_else(|_| url.to_string());

    masked
}
